#summary 辞書サイズの比較．

= 概要 =

Darts clone の利点を示すために，Darts と Darts clone を用いて構築される辞書のサイズを示します．
今回調査した辞書の内容は以下のようになっています．

 * MeCab
  * MeCab で ipadic を用いた場合の辞書（sys.dic）
 * ChaSen
  * ChaSen で ipadic を用いた場合の辞書（chadic.da）
 * Google N-gram
  * Google N-gmra コーパスの unigrams を登録した辞書
 * 日英単語
  * ipadic-2.6.3 と Wordnet-3.0 から構築した辞書

= 実験結果 =

== MeCab ==

MeCab を Ubuntu 8.04 上でコンパイルしたときに生成される辞書（sys.dic）のサイズを調査しました．
実験に使用したのは，mecab-0.97.tar.gz と mecab-ipadic-2.7.0-20070801.tar.gz の組み合わせです．
これらのアーカイブは以下のサイトから入手できます．

 * MeCab: Yet Another Part-of-Speech and Morphological Analyzer
  * http://mecab.sourceforge.net/

辞書構築までの手順は以下の通りです．
Darts clone を使用するときは，mecab-0.97.tar.gz に含まれる darts.h を darts-clone.h により置き換えました．

 # tar zxvf mecab-0.97.tar.gz
 # cd mecab-0.97
 # ./configure
 # make
 # make check
 # sudo make install
 # cd ..
 # tar zxvf mecab-ipadic-2.7.0-20070801.tar.gz
 # cd mecab-ipadic-2.7.0-20070801
 # ./configure
 # /usr/local/libexec/mecab/mecab-dict-index -d . -o . -f EUC-JP -t 文字コード

辞書サイズは以下のようになりました．
品詞や読みに割り当てられている領域の方がずっと大きいようで，全体から見ると大して効果はありません．
sys.dic のサイズが 15% ほど削減されるにとどまりました．

|| *文字コード* || *Darts* || *Darts clone* ||
||sjis||37,638,335||32,232,563||
||euc||37,779,919||32,245,051||
||utf8||49,199,027||41,587,051||

このままでは悲しいので，分かち書き用の辞書も構築してみました．
品詞などがなくなったおかげで，少し嬉しい結果になっています．

|| *文字コード* || *Darts* || *Darts clone* ||
||sjis||15,132,073||9,726,301||
||euc||15,273,657||9,738,789||
||utf8||17,700,673||10,088,697||

※ 分かち書き用の辞書は mecab-dict-index に -w オプションを与えることで構築できます．

== ChaSen ==

chasen-2.4.4 を Ubuntu 8.04 にインストールし，ipadic-2.7.0 から構築される辞書（chadic.da）のサイズを調査しました．
chadic.da 以外のファイルは合計 20MB 程度なため，全体の 1/4 弱が削減されたことになります．

|| *文字コード* || *Darts* || *Darts clone* ||
||utf8||11,432,440||3,816,376||

なお，文字コードには UTF-8 を採用しています．
以下のサイトを参考にインストールしました．

 * ChaSen -- 形態素解析器
  * http://chasen-legacy.sourceforge.jp/
 * 「ChaSen」をUTF-8対応で導入
  * http://www.crimson-snow.net/hmsvr/centos/memo/chasen_utf8.html

chasen-2.4.4 と ipadic-2.7.0 の組み合わせをインストールしたときの手順を以下に示します．

 # tar zxvf chasen-2.4.4.tar.gz
 # cd chasen-2.4.4
 # ./configure
 # make
 # make check
 # sudo make install
 # sudo vi /etc/ld.so.conf
{{{
/usr/local/lib # この一行を追加
}}}
 # sudo ldconfig
 # cd ..
 # tar zxvf ipadic-2.7.0.tar.gz
 # cd ipadic-2.7.0
 # ./configure
 # vi conv_utf-8.sh
{{{
#! /bin/sh
for file in $*
do
  if [ -f $file ]; then
    iconv -f euc-jp -t utf-8 $file > tmpfile
    mv tmpfile $file
  fi
done
exit
}}}
 # chmod +x conv_utf-8.sh
 # ./conv_utf-8.sh `*`.dic `*`.cha
 # {{{`chasen-config --mkchadic`/makemat}}} -i w
 # {{{`chasen-config --mkchadic`/makeda}}} -i w chadic `*`.dic
 # sudo make install

== Google N-gram ==

Google N-gram コーパスの unigram を使用して，大規模なキー集合に対する性能を調査しました．
Darts の辞書構築には mkdarts，Darts clone の辞書構築には mkdarts-clone を使用しています．
ただし，Darts clone の Darts::DoubleArray は構築できる辞書の規模に上限があるため，
英語の unigram については Darts::HugeDoubleArray を使用しています．

※ mkdarts-clone と darts-clone に -h オプションを与えると Darts::HugeDoubleArray を使用します．

|| *言語* || *キー数* || *ソース* || *Darts* || *Darts clone* ||
||日本語||2,565,427||50,784,220||162,689,912||36,857,172||
||英語||13,588,391||125,937,836||406,358,432||223,290,696||

日本語 unigram については，Darts clone のサイズは Darts の 1/4 以下になっています．
一方，英語 unigram については，Darts::HugeDoubleArray を使っていることもあり，1/2 程度になっています．

※ 日本語 unigram 使用時の差が大きい理由としては，長いカタカナが大量に含まれていることが挙げられます．

== 日英単語 ==

ipadic-2.6.3 の見出し語と WordNet-3.0 の英単語から Darts と Darts clone の辞書を構築し，サイズを調査しました．

|| *辞書ソース* || *Darts* || *Darts clone* ||
||ipadic-2.6.3||9,198,968||2,643,612||
||WordNet-3.0||7,526,800||2,016,964||

※ ipadic-2.6.3 の見出し語は文字コードを UTF-8 に変更しました．